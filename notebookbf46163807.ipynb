{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12705722,"sourceType":"datasetVersion","datasetId":8030108}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"54cfc9ec","cell_type":"markdown","source":"# Combined Credit Card Fraud Training (ULB + 2023)\n\nThis notebook merges the two datasets, reuses the same preparation techniques (feature engineering, stratified splits, scaling, class imbalance handling), and trains the same baseline models (Logistic Regression, Random Forest). We report Accuracy, Precision, Recall, F1, and ROC-AUC on a held-out test set. Target: ≥95% accuracy.\n\nNotes\n- Reads: `data/creditcard.csv/creditcard.csv` (ULB) and `data/creditcard.csv/creditcard_2023.csv` (2023)\n- Handles class imbalance with SMOTE on train only\n- Scaler: StandardScaler on train, applied to val/test\n- Models: Logistic Regression (balanced), Random Forest (balanced)\n- Metrics: train/val/test; plus cross-validation on train\n- Saves key artifacts under `results/`","metadata":{}},{"id":"40d54cd9","cell_type":"code","source":"# 1) Import Libraries and Set Seed\nimport os\nimport json\nimport math\nimport random\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Optional: IMBLEARN (SMOTE); will fallback if unavailable\ntry:\n    from imblearn.over_sampling import SMOTE  # type: ignore\n    IMBLEARN_AVAILABLE = True\nexcept Exception:\n    SMOTE = None  # type: ignore\n    IMBLEARN_AVAILABLE = False\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\n\nprint(\"Environment ready. Seed set to\", SEED)\nprint(\"imblearn available:\", IMBLEARN_AVAILABLE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T03:25:45.310841Z","iopub.execute_input":"2025-08-08T03:25:45.311196Z","iopub.status.idle":"2025-08-08T03:25:46.417323Z","shell.execute_reply.started":"2025-08-08T03:25:45.311171Z","shell.execute_reply":"2025-08-08T03:25:46.416531Z"}},"outputs":[{"name":"stdout","text":"Environment ready. Seed set to 42\nimblearn available: False\n","output_type":"stream"}],"execution_count":1},{"id":"955974ea","cell_type":"code","source":"# 2) Configure Paths and Hyperparameters\nfrom pathlib import Path\nimport os\n\n# Detect Kaggle environment and set paths accordingly\nif os.path.exists('/kaggle/input'):\n    # Try common dataset folder names users might upload to Kaggle\n    # Adjust these names if your Kaggle Dataset names differ\n    kaggle_base = Path('/kaggle/input')\n    # Attempt to find creditcard.csv and creditcard_2023.csv anywhere under /kaggle/input\n    def find_file(root: Path, name: str):\n        for p in root.rglob(name):\n            return p\n        return None\n    ULB_PATH = find_file(kaggle_base, 'creditcard.csv')\n    Y2023_PATH = find_file(kaggle_base, 'creditcard_2023.csv') or find_file(kaggle_base, 'credit_card_fraud_2023.csv')\nelse:\n    DATA_DIR = Path('data')\n    ULB_PATH = DATA_DIR / 'creditcard.csv' / 'creditcard.csv'\n    Y2023_PATH = DATA_DIR / 'creditcard.csv' / 'creditcard_2023.csv'\n\nTARGET_ACCURACY = 0.95\nSCALER_TYPE = 'standard'\nBALANCE_METHOD = 'smote'  # on train only\nTEST_SIZE = 0.2\nVAL_SIZE = 0.2  # of the remaining after test split\n\nOUTPUT_DIR = Path('results') / 'combined_training'\nOUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n\nprint('ULB path:', ULB_PATH)\nprint('2023 path:', Y2023_PATH)\nprint('Output dir:', OUTPUT_DIR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T03:25:46.418852Z","iopub.execute_input":"2025-08-08T03:25:46.419309Z","iopub.status.idle":"2025-08-08T03:25:46.441149Z","shell.execute_reply.started":"2025-08-08T03:25:46.419281Z","shell.execute_reply":"2025-08-08T03:25:46.439905Z"}},"outputs":[{"name":"stdout","text":"ULB path: /kaggle/input/creditcardfraudtraining/creditcard.csv\n2023 path: /kaggle/input/creditcardfraudtraining/creditcard_2023.csv\nOutput dir: results/combined_training\n","output_type":"stream"}],"execution_count":2},{"id":"90625088","cell_type":"code","source":"# 3) Load both datasets (handle large file) and inspect\nfrom zipfile import ZipFile\n\n\ndef find_file(root: Path, names):\n    names = names if isinstance(names, (list, tuple)) else [names]\n    for nm in names:\n        p = next(root.rglob(nm), None)\n        if p is not None:\n            return p\n    return None\n\n\ndef read_csv_maybe_zip(path: Path, nrows=None):\n    if path.suffix.lower() == '.zip':\n        with ZipFile(path, 'r') as zf:\n            # pick the first .csv inside\n            csv_names = [n for n in zf.namelist() if n.lower().endswith('.csv')]\n            if not csv_names:\n                raise FileNotFoundError(f'No CSV inside {path}')\n            with zf.open(csv_names[0]) as f:\n                return pd.read_csv(f, nrows=nrows)\n    else:\n        return pd.read_csv(path, nrows=nrows)\n\n\ndef safe_read_csv(path: Path, nrows=None):\n    try:\n        return read_csv_maybe_zip(path, nrows=None)\n    except Exception as e:\n        print(f\"Full read failed for {path.name}: {e}\\nFalling back to reading first {nrows or 200000} rows.\")\n        return read_csv_maybe_zip(path, nrows=nrows or 200000)\n\n# Resolve paths on Kaggle if not found\nif ULB_PATH is None or not Path(ULB_PATH).exists():\n    base = Path('/kaggle/input') if Path('/kaggle/input').exists() else Path('.')\n    ULB_PATH = find_file(base, ['creditcard.csv', 'creditcard.csv.zip'])\nif Y2023_PATH is None or not Path(Y2023_PATH).exists():\n    base = Path('/kaggle/input') if Path('/kaggle/input').exists() else Path('.')\n    Y2023_PATH = find_file(base, [\n        'creditcard_2023.csv',\n        'credit_card_fraud_2023.csv',\n        'creditcard_2023_cleaned.csv',\n        'credit_card_fraud_2023_cleaned.csv'\n    ])\n\nprint('Resolved ULB path:', ULB_PATH)\nprint('Resolved 2023 path:', Y2023_PATH)\nassert ULB_PATH is not None and Path(ULB_PATH).exists(), f\"Missing ULB dataset at {ULB_PATH}\"\nassert Y2023_PATH is not None and Path(Y2023_PATH).exists(), f\"Missing 2023 dataset at {Y2023_PATH}\"\n\ndf_ulb = safe_read_csv(Path(ULB_PATH))\ndf_2023 = safe_read_csv(Path(Y2023_PATH))\n\nprint('ULB shape:', df_ulb.shape)\nprint('2023 shape:', df_2023.shape)\nprint('ULB columns (head):', list(df_ulb.columns)[:10])\nprint('2023 columns (head):', list(df_2023.columns)[:10])\n\n# 4) Harmonize target and align feature space\n# Identify likely target columns\npossible_targets = ['Class','class','fraud','Fraud','is_fraud','target','label']\n\ndef find_target(df):\n    for c in possible_targets:\n        if c in df.columns and df[c].nunique() == 2:\n            return c\n    return None\n\ntgt_ulb = find_target(df_ulb)\ntgt_2023 = find_target(df_2023)\nprint('Target ULB:', tgt_ulb, '| Target 2023:', tgt_2023)\nassert tgt_ulb is not None and tgt_2023 is not None, 'Could not identify target in one or both datasets.'\n\n# Standardize target name\ndf_ulb = df_ulb.rename(columns={tgt_ulb: 'target'})\ndf_2023 = df_2023.rename(columns={tgt_2023: 'target'})\n\n# Keep numeric columns + engineered ones later (drop obvious identifiers if exist)\nnum_ulb = df_ulb.select_dtypes(include=[np.number]).columns.tolist()\nnum_2023 = df_2023.select_dtypes(include=[np.number]).columns.tolist()\n\n# Ensure 'target' present and kept at end\nnum_ulb = [c for c in num_ulb if c != 'target']\nnum_2023 = [c for c in num_2023 if c != 'target']\n\n# Common numeric columns\ncommon_numeric = sorted(list(set(num_ulb).intersection(set(num_2023))))\nprint('Common numeric features:', len(common_numeric))\n\n# Minimal feature engineering similar to previous scripts\ndef add_engineered_features(df):\n    df_eng = df.copy()\n    if 'Amount' in df_eng.columns:\n        df_eng['Amount_log'] = np.log1p(df_eng['Amount'])\n        df_eng['Amount_sqrt'] = np.sqrt(np.maximum(df_eng['Amount'], 0))\n    if 'Time' in df_eng.columns:\n        df_eng['Hour'] = ((df_eng['Time'] / 3600) % 24)\n        df_eng['Day'] = ((df_eng['Time'] / (3600*24)) % 7)\n        rng = df_eng['Time'].max() - df_eng['Time'].min()\n        if rng != 0:\n            df_eng['Time_normalized'] = (df_eng['Time'] - df_eng['Time'].min()) / rng\n        else:\n            df_eng['Time_normalized'] = 0.0\n    # V-stats if available\n    v_cols = [c for c in df_eng.columns if isinstance(c, str) and c.startswith('V')]\n    if len(v_cols) > 0:\n        df_eng['V_mean'] = df_eng[v_cols].mean(axis=1)\n        df_eng['V_std'] = df_eng[v_cols].std(axis=1)\n        df_eng['V_sum'] = df_eng[v_cols].sum(axis=1)\n        df_eng['V_max'] = df_eng[v_cols].max(axis=1)\n        df_eng['V_min'] = df_eng[v_cols].min(axis=1)\n    return df_eng\n\nulb_eng = add_engineered_features(df_ulb)\ny2023_eng = add_engineered_features(df_2023)\n\n# Recompute numeric lists including engineered features\nnum_ulb2 = [c for c in ulb_eng.select_dtypes(include=[np.number]).columns if c != 'target']\nnum_2023_2 = [c for c in y2023_eng.select_dtypes(include=[np.number]).columns if c != 'target']\ncommon_numeric2 = sorted(list(set(num_ulb2).intersection(set(num_2023_2))))\nprint('Common numeric features after engineering:', len(common_numeric2))\n\n# Build combined DataFrame with common features and target\nulb_final = ulb_eng[common_numeric2 + ['target']].copy()\ny2023_final = y2023_eng[common_numeric2 + ['target']].copy()\n\ncombined = pd.concat([ulb_final, y2023_final], axis=0, ignore_index=True)\ncombined = combined.dropna().drop_duplicates()\nprint('Combined shape:', combined.shape)\nprint('Fraud rate (overall):', combined['target'].mean()*100, '%')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T03:25:46.442194Z","iopub.execute_input":"2025-08-08T03:25:46.443034Z","iopub.status.idle":"2025-08-08T03:26:01.555681Z","shell.execute_reply.started":"2025-08-08T03:25:46.442998Z","shell.execute_reply":"2025-08-08T03:26:01.554643Z"}},"outputs":[{"name":"stdout","text":"Resolved ULB path: /kaggle/input/creditcardfraudtraining/creditcard.csv\nResolved 2023 path: /kaggle/input/creditcardfraudtraining/creditcard_2023.csv\nULB shape: (284807, 31)\n2023 shape: (568630, 31)\nULB columns (head): ['Time', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9']\n2023 columns (head): ['id', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9']\nTarget ULB: Class | Target 2023: Class\nCommon numeric features: 29\nCommon numeric features after engineering: 36\nCombined shape: (844292, 37)\nFraud rate (overall): 33.73086562468909 %\n","output_type":"stream"}],"execution_count":3},{"id":"42b5373b","cell_type":"code","source":"# 5) Stratified Train/Val/Test Split\nfeatures = [c for c in combined.columns if c != 'target']\nX = combined[features].values\ny = combined['target'].values\n\nX_temp, X_test, y_temp, y_test = train_test_split(\n    X, y, test_size=TEST_SIZE, random_state=SEED, stratify=y\n)\nval_size_adj = VAL_SIZE / (1 - TEST_SIZE)\nX_train, X_val, y_train, y_val = train_test_split(\n    X_temp, y_temp, test_size=val_size_adj, random_state=SEED, stratify=y_temp\n)\n\nprint('Split sizes:', X_train.shape, X_val.shape, X_test.shape)\nprint('Train fraud rate:', y_train.mean()*100, '%')\nprint('Val fraud rate:', y_val.mean()*100, '%')\nprint('Test fraud rate:', y_test.mean()*100, '%')\n\n# 6) Scale + Balance (train only)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_val_scaled = scaler.transform(X_val)\nX_test_scaled = scaler.transform(X_test)\n\n# Balance training data\nif IMBLEARN_AVAILABLE and SMOTE is not None:\n    sm = SMOTE(random_state=SEED)\n    X_train_bal, y_train_bal = sm.fit_resample(X_train_scaled, y_train)\n    print('Used SMOTE for balancing.')\nelse:\n    # Simple random oversampling fallback\n    print('SMOTE not available; using simple random oversampling fallback.')\n    y_series = pd.Series(y_train)\n    count_0 = int((y_series == 0).sum())\n    count_1 = int((y_series == 1).sum())\n    maj_label = 0 if count_0 >= count_1 else 1\n    min_label = 1 - maj_label\n\n    X_m = X_train_scaled[y_train == maj_label]\n    X_n = X_train_scaled[y_train == min_label]\n    y_m = y_train[y_train == maj_label]\n    y_n = y_train[y_train == min_label]\n\n    deficit = len(y_m) - len(y_n)\n    idx = np.random.choice(len(X_n), size=deficit, replace=True)\n    X_syn = X_n[idx]\n    y_syn = y_n[idx]\n\n    X_train_bal = np.vstack([X_train_scaled, X_syn])\n    y_train_bal = np.hstack([y_train, y_syn])\n\nprint('Balanced train shapes:', X_train_bal.shape, len(y_train_bal))\nprint('Balanced class distribution:', pd.Series(y_train_bal).value_counts().to_dict())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T03:26:01.557367Z","iopub.execute_input":"2025-08-08T03:26:01.557640Z","iopub.status.idle":"2025-08-08T03:26:03.368133Z","shell.execute_reply.started":"2025-08-08T03:26:01.557618Z","shell.execute_reply":"2025-08-08T03:26:03.367176Z"}},"outputs":[{"name":"stdout","text":"Split sizes: (506574, 36) (168859, 36) (168859, 36)\nTrain fraud rate: 33.73070864276493 %\nVal fraud rate: 33.731101096180836 %\nTest fraud rate: 33.731101096180836 %\nSMOTE not available; using simple random oversampling fallback.\nBalanced train shapes: (671406, 36) 671406\nBalanced class distribution: {1: 335703, 0: 335703}\n","output_type":"stream"}],"execution_count":4},{"id":"0ceb9b01","cell_type":"code","source":"# 7-10) Train models and evaluate\n\ndef evaluate_split(name, y_true, y_pred, y_proba=None):\n    acc = accuracy_score(y_true, y_pred)\n    prec = precision_score(y_true, y_pred, zero_division=0)\n    rec = recall_score(y_true, y_pred, zero_division=0)\n    f1 = f1_score(y_true, y_pred, zero_division=0)\n    roc = roc_auc_score(y_true, y_proba if y_proba is not None else y_pred)\n    cm = confusion_matrix(y_true, y_pred)\n    print(f\"\\n{name} Metrics:\")\n    print(f\"Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f} | F1: {f1:.4f} | ROC-AUC: {roc:.4f}\")\n    print('Confusion Matrix:\\n', cm)\n    print('\\nClassification Report:\\n', classification_report(y_true, y_pred, digits=4))\n    return {'accuracy':acc,'precision':prec,'recall':rec,'f1':f1,'roc_auc':roc,'cm':cm}\n\n# Train only Random Forest for speed\nmodels = {\n    'Random_Forest': RandomForestClassifier(n_estimators=150, random_state=SEED, class_weight='balanced', n_jobs=-1, max_depth=12)\n}\n\nresults = {}\n\nfor model_name, model in models.items():\n    print(f\"\\nTraining {model_name}...\")\n    model.fit(X_train_bal, y_train_bal)\n\n    # Train metrics\n    ytr_pred = model.predict(X_train_bal)\n    ytr_proba = model.predict_proba(X_train_bal)[:,1] if hasattr(model, 'predict_proba') else None\n    train_metrics = evaluate_split(f'{model_name} - Train', y_train_bal, ytr_pred, ytr_proba)\n\n    # Val metrics\n    yv_pred = model.predict(X_val_scaled)\n    yv_proba = model.predict_proba(X_val_scaled)[:,1] if hasattr(model, 'predict_proba') else None\n    val_metrics = evaluate_split(f'{model_name} - Val', y_val, yv_proba >= 0.5 if yv_proba is not None else yv_pred, yv_proba)\n\n    # Test metrics\n    yt_pred = model.predict(X_test_scaled)\n    yt_proba = model.predict_proba(X_test_scaled)[:,1] if hasattr(model, 'predict_proba') else None\n    test_metrics = evaluate_split(f'{model_name} - Test', y_test, yt_proba >= 0.5 if yt_proba is not None else yt_pred, yt_proba)\n\n    results[model_name] = {\n        'train': train_metrics,\n        'val': val_metrics,\n        'test': test_metrics,\n        'model': model\n    }\n\n    # If we only need to report and stop here, break out\n    if 'STOP_AFTER_TEST' in globals() and STOP_AFTER_TEST:\n        print('\\nSTOP_AFTER_TEST is True: skipping cross-validation, threshold tuning, and file saving.')\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T03:26:03.369055Z","iopub.execute_input":"2025-08-08T03:26:03.369382Z","iopub.status.idle":"2025-08-08T03:32:31.119780Z","shell.execute_reply.started":"2025-08-08T03:26:03.369347Z","shell.execute_reply":"2025-08-08T03:32:31.118221Z"}},"outputs":[{"name":"stdout","text":"\nTraining Random_Forest...\n\nRandom_Forest - Train Metrics:\nAccuracy: 0.9960 | Precision: 0.9985 | Recall: 0.9936 | F1: 0.9960 | ROC-AUC: 0.9999\nConfusion Matrix:\n [[335199    504]\n [  2164 333539]]\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.9936    0.9985    0.9960    335703\n           1     0.9985    0.9936    0.9960    335703\n\n    accuracy                         0.9960    671406\n   macro avg     0.9960    0.9960    0.9960    671406\nweighted avg     0.9960    0.9960    0.9960    671406\n\n\nRandom_Forest - Val Metrics:\nAccuracy: 0.9958 | Precision: 0.9965 | Recall: 0.9910 | F1: 0.9937 | ROC-AUC: 0.9998\nConfusion Matrix:\n [[111700    201]\n [   510  56448]]\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.9955    0.9982    0.9968    111901\n           1     0.9965    0.9910    0.9937     56958\n\n    accuracy                         0.9958    168859\n   macro avg     0.9960    0.9946    0.9953    168859\nweighted avg     0.9958    0.9958    0.9958    168859\n\n\nRandom_Forest - Test Metrics:\nAccuracy: 0.9960 | Precision: 0.9964 | Recall: 0.9918 | F1: 0.9941 | ROC-AUC: 0.9998\nConfusion Matrix:\n [[111695    206]\n [   465  56493]]\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.9959    0.9982    0.9970    111901\n           1     0.9964    0.9918    0.9941     56958\n\n    accuracy                         0.9960    168859\n   macro avg     0.9961    0.9950    0.9956    168859\nweighted avg     0.9960    0.9960    0.9960    168859\n\n","output_type":"stream"}],"execution_count":5},{"id":"1b491651-d79f-4f96-b66e-8191e299c50d","cell_type":"code","source":"# Export trained model, scaler, features, and threshold for deployment\nimport os, json, pickle, zipfile\nfrom pathlib import Path\nfrom datetime import datetime\nfrom IPython.display import FileLink\n\n# Pick best model (prefer Random Forest if available)\nexport_model_name = None\nif 'results' in globals() and isinstance(results, dict):\n    if 'Random_Forest' in results:\n        export_model_name = 'Random_Forest'\n    else:\n        # fall back to the highest test accuracy\n        export_model_name = max(results.keys(), key=lambda k: results[k]['test']['accuracy'])\nelse:\n    raise RuntimeError('No trained results found. Please run the training cells first.')\n\nmodel_obj = results[export_model_name]['model']\nscaler_obj = scaler if 'scaler' in globals() else None\nfeature_list = features if 'features' in globals() else None\n\nthr = 0.5\nif 'threshold_results' in globals() and export_model_name in threshold_results:\n    thr = float(threshold_results[export_model_name]['threshold'])\n\n# Prep export directory (Kaggle-friendly)\nwork_base = Path('/kaggle/working') if Path('/kaggle/working').exists() else OUTPUT_DIR\nexport_dir = work_base / 'combined_model'\nexport_dir.mkdir(parents=True, exist_ok=True)\n\n# Save artifacts\nwith open(export_dir / 'model.pkl', 'wb') as f:\n    pickle.dump(model_obj, f)\n\nif scaler_obj is not None:\n    with open(export_dir / 'scaler.pkl', 'wb') as f:\n        pickle.dump(scaler_obj, f)\n\nif feature_list is not None:\n    with open(export_dir / 'features.json', 'w') as f:\n        json.dump({'features': feature_list}, f, indent=2)\n\nwith open(export_dir / 'threshold.json', 'w') as f:\n    json.dump({'threshold': thr}, f, indent=2)\n\n# Some metadata + scores\nmeta = {\n    'exported_at': datetime.utcnow().isoformat() + 'Z',\n    'model_name': export_model_name,\n    'val_metrics': results[export_model_name]['val'],\n    'test_metrics': results[export_model_name]['test'],\n}\nwith open(export_dir / 'metadata.json', 'w') as f:\n    json.dump(meta, f, indent=2, default=lambda o: o.tolist() if hasattr(o, 'tolist') else o)\n\n# Zip the folder for easy download\nzip_path = work_base / 'combined_model_artifacts.zip'\nwith zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as z:\n    for p in export_dir.iterdir():\n        z.write(p, arcname=f'combined_model/{p.name}')\n\nprint('Exported artifacts to:', export_dir)\nprint('Zipped at:', zip_path)\ntry:\n    display(FileLink(zip_path))\nexcept Exception:\n    pass\n\nprint('\\nTo download on Kaggle:')\nprint('- Use the link above or open the “Output” panel and download combined_model_artifacts.zip.')\nprint('- You can also “Save Version” and fetch files from the notebook version outputs.')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-08T03:32:31.121931Z","iopub.execute_input":"2025-08-08T03:32:31.122307Z","iopub.status.idle":"2025-08-08T03:32:31.903609Z","shell.execute_reply.started":"2025-08-08T03:32:31.122253Z","shell.execute_reply":"2025-08-08T03:32:31.902606Z"}},"outputs":[{"name":"stdout","text":"Exported artifacts to: /kaggle/working/combined_model\nZipped at: /kaggle/working/combined_model_artifacts.zip\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"/kaggle/working/combined_model_artifacts.zip","text/html":"<a href='/kaggle/working/combined_model_artifacts.zip' target='_blank'>/kaggle/working/combined_model_artifacts.zip</a><br>"},"metadata":{}},{"name":"stdout","text":"\nTo download on Kaggle:\n- Use the link above or open the “Output” panel and download combined_model_artifacts.zip.\n- You can also “Save Version” and fetch files from the notebook version outputs.\n","output_type":"stream"}],"execution_count":6}]}